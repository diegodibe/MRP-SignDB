{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LSE_OpenPose_v25c.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X38L6tanrnrB"
      },
      "source": [
        "# Pose Detection with OpenPose\n",
        "\n",
        "This notebook uses an open source project [CMU-Perceptual-Computing-Lab/openpose](https://github.com/CMU-Perceptual-Computing-Lab/openpose.git) to detect/track multi person poses on a given youtube video.\n",
        "\n",
        "For other deep-learning Colab notebooks, visit [tugstugi/dl-colab-notebooks](https://github.com/tugstugi/dl-colab-notebooks).\n",
        "\n",
        "\n",
        "## Install OpenPose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJeeb66V7AMf"
      },
      "source": [
        "Build Openpose. Takes 20-30 minutes\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOdkDhb6ga6N",
        "outputId": "bd1dd6db-8469-4823-fca5-af1996992a6b"
      },
      "source": [
        "import os\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "git_repo_url = 'https://github.com/CMU-Perceptual-Computing-Lab/openpose.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "\n",
        "#Cloning the openpose github repository and making a new project folder in drive alongwith installing Cmake to bind C++ code in Python\n",
        "if 1 or not exists(project_name):\n",
        "  !rm -rf openpose\n",
        "  print(\"install new CMake becaue of CUDA10\")\n",
        "  if not exists('cmake-3.13.0-Linux-x86_64.tar.gz'):\n",
        "    !wget -q https://cmake.org/files/v3.13/cmake-3.13.0-Linux-x86_64.tar.gz\n",
        "  !tar xfz cmake-3.13.0-Linux-x86_64.tar.gz --strip-components=1 -C /usr/local\n",
        "\n",
        "  print(\"clone openpose\")\n",
        "  !git clone -q --depth 1 $git_repo_url\n",
        "  print(\"CMakelist.txt's caffe fix\")\n",
        "  !sed -i 's/execute_process(COMMAND git checkout master WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}\\/3rdparty\\/caffe)/execute_process(COMMAND git checkout f019d0dfe86f49d1140961f8c7dec22130c83154 WORKING_DIRECTORY ${CMAKE_SOURCE_DIR}\\/3rdparty\\/caffe)/g' openpose/CMakeLists.txt\n",
        "  print(\"install system dependencies\")\n",
        "  !apt-get -qq install -y libatlas-base-dev libprotobuf-dev libleveldb-dev libsnappy-dev libhdf5-serial-dev protobuf-compiler libgflags-dev libgoogle-glog-dev liblmdb-dev opencl-headers ocl-icd-opencl-dev libviennacl-dev\n",
        "  print(\"build openpose\")\n",
        "  !cd openpose && rm -rf build || true && mkdir build && cd build && cmake -DBUILD_PYTHON=ON .. && make -j`nproc`\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "install new CMake becaue of CUDA10\n",
            "^C\n",
            "clone openpose\n",
            "^C\n",
            "CMakelist.txt's caffe fix\n",
            "sed: can't read openpose/CMakeLists.txt: No such file or directory\n",
            "install system dependencies\n",
            "build openpose\n",
            "/bin/bash: line 0: cd: openpose: No such file or directory\n",
            "/bin/bash: line 1:  6507 Segmentation fault      cmake -DBUILD_PYTHON=ON ..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChJHjkNb7O3k"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QELQv8EuSQrS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6280bf7b-66b9-4c08-f678-df555f6be4d2"
      },
      "source": [
        "#Importing all the libraries\n",
        "\n",
        "!pip install xlrd\n",
        "from os.path import exists, join, basename, splitext\n",
        "import os\n",
        "import cv2\n",
        "from os import listdir\n",
        "import shutil\n",
        "from os.path import isfile, join\n",
        "import sys\n",
        "import cv2\n",
        "import os\n",
        "from sys import platform\n",
        "import argparse\n",
        "import numpy as np\n",
        "from moviepy.editor import VideoFileClip\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import csv\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b3465216/45929032 bytes (7.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b7634944/45929032 bytes (16.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b11862016/45929032 bytes (25.8%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b16097280/45929032 bytes (35.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b20267008/45929032 bytes (44.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b24469504/45929032 bytes (53.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b28704768/45929032 bytes (62.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b32948224/45929032 bytes (71.7%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b37019648/45929032 bytes (80.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b41123840/45929032 bytes (89.5%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45285376/45929032 bytes (98.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag4ey7oN7UUp"
      },
      "source": [
        "Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VKZHnwuYuVu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "938d0778-d5aa-46e4-dc19-6c5ed5fd35ad"
      },
      "source": [
        "#This takes some times and for some reason it results in timeout for me, but still it mounts the drive even after crashing due to timeout. Proceed with running the next cell after the timeout\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/\\drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AY0e-g6HuyHucGYj09_NKLeTtNmmnDzPVV1D7TaC_Ykv-7OxDWeKB8R6vgw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TIMEOUT",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTIMEOUT\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-4bb4cb4639e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/\\drive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mdrive_exited\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0moauth_failed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mdomain_disabled_drivefs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m     ])\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect\u001b[0;34m(self, pattern, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mcompiled_pattern_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_pattern_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         return self.expect_list(compiled_pattern_list,\n\u001b[0;32m--> 344\u001b[0;31m                 timeout, searchwindowsize, async_)\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     def expect_list(self, pattern_list, timeout=-1, searchwindowsize=-1,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/spawnbase.py\u001b[0m in \u001b[0;36mexpect_list\u001b[0;34m(self, pattern_list, timeout, searchwindowsize, async_, **kw)\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mexpect_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 372\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m     def expect_exact(self, pattern_list, timeout=-1, searchwindowsize=-1,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mexpect_loop\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTIMEOUT\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrored\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pexpect/expect.py\u001b[0m in \u001b[0;36mtimeout\u001b[0;34m(self, err)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mexc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTIMEOUT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m    \u001b[0;31m# in Python 3.x we can use \"raise exc from None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merrored\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTIMEOUT\u001b[0m: <pexpect.popen_spawn.PopenSpawn object at 0x7f905b168d68>\nsearcher: searcher_re:\n    0: re.compile('google.colab.drive MOUNTED')\n    1: re.compile('root@aad966726cb5-7fef892bde9d47dda1c0e4be667cfd89: ')\n    2: re.compile('(Go to this URL in a browser: https://.*)$')\n    3: re.compile('Drive File Stream encountered a problem and has stopped')\n    4: re.compile('drive EXITED')\n    5: re.compile('Authorization failed')\n    6: re.compile('The domain policy has disabled Drive File Stream')\n<pexpect.popen_spawn.PopenSpawn object at 0x7f905b168d68>\nsearcher: searcher_re:\n    0: re.compile('google.colab.drive MOUNTED')\n    1: re.compile('root@aad966726cb5-7fef892bde9d47dda1c0e4be667cfd89: ')\n    2: re.compile('(Go to this URL in a browser: https://.*)$')\n    3: re.compile('Drive File Stream encountered a problem and has stopped')\n    4: re.compile('drive EXITED')\n    5: re.compile('Authorization failed')\n    6: re.compile('The domain policy has disabled Drive File Stream')"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxAbVqbb7YYl"
      },
      "source": [
        "Define Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vlAuA4OqtOo"
      },
      "source": [
        "#This function convert videos into frames since Openpose runs on images and not videos\n",
        "def get_frames(img_frame_path,video_path,video_name):\n",
        "    if os.path.exists(img_frame_path):\n",
        "      shutil.rmtree(img_frame_path)\n",
        "    os.makedirs(img_frame_path)    \n",
        "    os.chdir(video_path)\n",
        "    cap = cv2.VideoCapture(video_name)\n",
        "    i = 0\n",
        "    p = 0\n",
        "    # a variable to set how many frames you want to skip\n",
        "    frame_skip = 4 #This will give a frame rate of 5 FPS, change to get different FPS\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        if i > frame_skip - 1:\n",
        "            os.chdir(img_frame_path)\n",
        "            cv2.imwrite('test_'+str(p)+'.jpg', frame)\n",
        "            i = 0\n",
        "            p = p+1\n",
        "            continue\n",
        "        i += 1\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    return p\n",
        "\n",
        "\n",
        "#This function converts frame numbers into timestamps to be used for segmentation\n",
        "def time_stamp_fn(len_frame_tot,frame_array,clip_location):\n",
        "\n",
        "  clip = VideoFileClip(clip_location)\n",
        "  duration = clip.duration\n",
        "  time = duration/len_frame_tot\n",
        "  print(time)\n",
        "  time_stop = [time * i for i in frame_array]\n",
        "  return time_stop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFOeAWJH7bJE"
      },
      "source": [
        "Main Loop (Change only the stuff in the block )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2J7Xds4m0wGd",
        "outputId": "65485d7e-9490-41ae-c44a-87ac0b693a45"
      },
      "source": [
        "######### ONLY CHANGE DIRECTORIES WITHIN THIS BLOCK #########\r\n",
        "\r\n",
        "#Below directories change it to location where you want to keep the frames of the video. The frames will automatically delete for new videos run so be sure to clean the trash regularly for space in your drive\r\n",
        "image_dir = r'/content/drive/My Drive/openpose_video/test1'\r\n",
        "img_frame_path = \"/content/drive/My Drive/openpose_video/test1\"\r\n",
        "\r\n",
        "\r\n",
        "#Change the directory below to the folder where you want the output\r\n",
        "output_dir = \"/content/drive/My Drive/openpose_video/output\"\r\n",
        "\r\n",
        "\r\n",
        "#Change the directory below to the folder where your videos are. Keep ONLY the files you want to process. Keep rest of the videos in a separate folder somewhere \r\n",
        "video_path = \"/content/drive/My Drive/openpose_video/vids\"\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "############### End of Block ###############################\r\n",
        "\r\n",
        "\r\n",
        "#Defining an empty array to store the name of video and bounding box co-ordinates for the sign translator \r\n",
        "vid_name_all = []\r\n",
        "x1_all = []\r\n",
        "x2_all = []\r\n",
        "y1_all = []\r\n",
        "y2_all = []\r\n",
        "\r\n",
        "\r\n",
        "vids = os.listdir(video_path)\r\n",
        "print(vids)\r\n",
        "count_video = 0\r\n",
        "for video_name in vids:\r\n",
        "  print(video_name)\r\n",
        "  num_frames = get_frames(img_frame_path,video_path,video_name)\r\n",
        "  print(\"Finished making frames from video\")\r\n",
        "  flag = False\r\n",
        "  try:\r\n",
        "      try:\r\n",
        "          # Windows Import (Not useful since we are using Colab which is Ubuntu), always goes in else loop\r\n",
        "          if platform == \"win32\":\r\n",
        "              sys.path.append(dir_path + '/../../python/openpose/Release');\r\n",
        "              os.environ['PATH']  = os.environ['PATH'] + ';' + dir_path + '/../../x64/Release;' +  dir_path + '/../../bin;'\r\n",
        "              import pyopenpose as op\r\n",
        "          else:\r\n",
        "              sys.path.append('/content/openpose/build/python');\r\n",
        "              from openpose import pyopenpose as op\r\n",
        "\r\n",
        "      except ImportError as e:\r\n",
        "          print('Error: OpenPose library could not be found. Did you enable `BUILD_PYTHON` in CMake and have this Python script in the right folder?')\r\n",
        "          raise e\r\n",
        "\r\n",
        "      #The below block of code is to set up Openpose, it was provided by the authors of Openpose\r\n",
        "\r\n",
        "      # Flags\r\n",
        "      parser = argparse.ArgumentParser()\r\n",
        "      parser.add_argument(\"--image_path\", default=\"/content/openpose/examples/media/COCO_val2014_000000000241.jpg\", help=\"Process an image. Read all standard formats (jpg, png, bmp, etc.).\")\r\n",
        "      args = parser.parse_known_args()\r\n",
        "\r\n",
        "      # Custom Params (refer to include/openpose/flags.hpp for more parameters)\r\n",
        "      params = dict()\r\n",
        "      params[\"model_folder\"] = \"/content/openpose/models\"\r\n",
        "      params[\"face\"] = True\r\n",
        "      params[\"hand\"] = True\r\n",
        "\r\n",
        "      # Add others in path?\r\n",
        "      for i in range(0, len(args[1])):\r\n",
        "          curr_item = args[1][i]\r\n",
        "          if i != len(args[1])-1: next_item = args[1][i+1]\r\n",
        "          else: next_item = \"1\"\r\n",
        "          if \"--\" in curr_item and \"--\" in next_item:\r\n",
        "              key = curr_item.replace('-','')\r\n",
        "              if key not in params:  params[key] = \"1\"\r\n",
        "          elif \"--\" in curr_item and \"--\" not in next_item:\r\n",
        "              key = curr_item.replace('-','')\r\n",
        "              if key not in params: params[key] = next_item\r\n",
        "\r\n",
        "      # Starting OpenPose\r\n",
        "      opWrapper = op.WrapperPython()\r\n",
        "      opWrapper.configure(params)\r\n",
        "      opWrapper.start()\r\n",
        "\r\n",
        "      #listing down all the frames obtained from the video\r\n",
        "      a= []\r\n",
        "      directory = image_dir\r\n",
        "      for filename in os.listdir(directory):\r\n",
        "          #print(filename)\r\n",
        "          if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\r\n",
        "              #print(os.path.join(directory, filename))\r\n",
        "              a.append(os.path.join(directory, filename))\r\n",
        "          else:\r\n",
        "              continue\r\n",
        "\r\n",
        "      #Some empty array defined so that results from each frame can be appended and worked on in the end\r\n",
        "\r\n",
        "      pose_matrix=[]\r\n",
        "      face_matrix = []\r\n",
        "      lefthand_matrix = []\r\n",
        "      righthand_matrix = []\r\n",
        "\r\n",
        "\r\n",
        "      xminmatrix = []\r\n",
        "      xmaxmatrix = []\r\n",
        "      yminmatrix = []\r\n",
        "      ymaxmatrix = []\r\n",
        "\r\n",
        "\r\n",
        "      facearray = []\r\n",
        "      lefthandarray = []\r\n",
        "      righthandarray = []\r\n",
        "      posearray = []\r\n",
        "      frame_array = []\r\n",
        "      frame = 0\r\n",
        "\r\n",
        "\r\n",
        "      # Looping for current and next frmae\r\n",
        "      for path0, path1 in zip(a,a[1:]):\r\n",
        "        frame = frame + 1    #Increase the frame count by 1\r\n",
        "        people_present_flag = 1 #This flag is toggled when there are some people detected in the frame, used later on to enter specific loops \r\n",
        "\r\n",
        "        add_distance = 0\r\n",
        "\r\n",
        "        #Python wrapper for first image\r\n",
        "        datum0 = op.Datum()\r\n",
        "        imageToProcess0 = cv2.imread(path0)\r\n",
        "        datum0.cvInputData = imageToProcess0\r\n",
        "        opWrapper.emplaceAndPop(op.VectorDatum([datum0]))\r\n",
        "        \r\n",
        "        #These are the hand, pose, and face keypoints for first image\r\n",
        "        lefthand0 = (datum0.handKeypoints[0])\r\n",
        "        righthand0 = (datum0.handKeypoints[1])\r\n",
        "        pose0 = datum0.poseKeypoints\r\n",
        "        face0 = datum0.faceKeypoints \r\n",
        "\r\n",
        "        #Python wrapper for first image\r\n",
        "        datum1 = op.Datum()\r\n",
        "        imageToProcess1 = cv2.imread(path1)\r\n",
        "        datum1.cvInputData = imageToProcess1\r\n",
        "        opWrapper.emplaceAndPop(op.VectorDatum([datum1]))\r\n",
        "        \r\n",
        "        #These are the hand, pose, and face keypoints for first image\r\n",
        "        lefthand1 = (datum1.handKeypoints[0])\r\n",
        "        righthand1 = (datum1.handKeypoints[1])\r\n",
        "        pose1 = datum1.poseKeypoints\r\n",
        "        face1 = datum1.faceKeypoints\r\n",
        "\r\n",
        "        #When no face is detected in current or next frame, there is no need to analyze hence append zeros to all arrays\r\n",
        "        if datum0.faceKeypoints is None or datum1.faceKeypoints is None:\r\n",
        "          facearray.append(np.zeros((70,3)))\r\n",
        "          posearray.append(np.zeros((25,3)))\r\n",
        "          lefthandarray.append(np.zeros((21,3)))\r\n",
        "          righthandarray.append(np.zeros((21,3)))\r\n",
        "          people_present_flag = 0\r\n",
        "        \r\n",
        "\r\n",
        "        else:\r\n",
        "          #Otherwise find the right most keypoint of the face and see the index to who it belongs to\r\n",
        "          rightmost = np.amax(face0[:,:,0],axis = 1)\r\n",
        "          ###### If you expect the sign translator to be on the left side of the screen uncomment the definition of 'rightmost' below and comment out the definition of 'rightmost' above\r\n",
        "          #rightmost = np.amin(face0[:,:,0],axis = 1)\r\n",
        "          person_index1=np.argmax(rightmost)\r\n",
        "          person_index = person_index1\r\n",
        " \r\n",
        "          #Find keypoints X and Y of sign translator\r\n",
        "          translatorfaceX = face0[person_index,:,0]\r\n",
        "          translatorleftX = lefthand0[person_index,:,0]\r\n",
        "          translatorrightX = righthand0[person_index,:,0]\r\n",
        "          translatorposeX = pose0[person_index,:,0]\r\n",
        "          if (face0[person_index,51,1] >0  and face0[person_index,22,1] > 0):\r\n",
        "            add_distance = face0[person_index,51,1] - face0[person_index,22,1] \r\n",
        "          translatorfaceY = face0[person_index,:,1]\r\n",
        "          translatorleftY = lefthand0[person_index,:,1]\r\n",
        "          translatorrightY = righthand0[person_index,:,1]\r\n",
        "          translatorposeY = pose0[person_index,:,1]\r\n",
        "\r\n",
        "\r\n",
        "          #This loop is entered to find the bounds of sign translator (4 co-ordinates) in the image\r\n",
        "          if (sum(translatorfaceX))>0 and (sum(translatorleftX))>0 and (sum(translatorrightX))>0 and (sum(translatorposeX))>0 and (sum(translatorfaceY))>0 and (sum(translatorleftY))>0 and (sum(translatorrightY))>0 and (sum(translatorposeY))>0 :\r\n",
        "            #The 4 co-ordinates\r\n",
        "            leftpointx = min(np.min(translatorfaceX[np.nonzero(translatorfaceX)]), np.min(translatorleftX[np.nonzero(translatorleftX)]),np.min(translatorrightX[np.nonzero(translatorrightX)]),np.min(translatorposeX[np.nonzero(translatorposeX)]))\r\n",
        "            rightpointx = max(np.max(translatorfaceX[np.nonzero(translatorfaceX)]), np.max(translatorleftX[np.nonzero(translatorleftX)]),np.max(translatorrightX[np.nonzero(translatorrightX)]),np.max(translatorposeX[np.nonzero(translatorposeX)]))\r\n",
        "            #Openpose only gives keypoints till eyebrows, so we extend it to cover the entire head\r\n",
        "            uppointy = face0[person_index,21,1] - 0.33*(pose0[person_index,1,1] - pose0[person_index,0,1])\r\n",
        "            downpointy = max(np.max(translatorfaceY[np.nonzero(translatorfaceY)]), np.max(translatorleftY[np.nonzero(translatorleftY)]),np.max(translatorrightY[np.nonzero(translatorrightY)]),np.max(translatorposeY[np.nonzero(translatorposeY)]))\r\n",
        "            \r\n",
        "            #Append all sign translator coordinates for a given frame in a matrix. We will calculate the global sign translator coordinates of a video later on \r\n",
        "            xminmatrix.append(leftpointx)\r\n",
        "            xmaxmatrix.append(rightpointx)\r\n",
        "            if (face0[person_index,21,1]>0) and (pose0[person_index,1,1])>0 and (pose0[person_index,0,1])>0:\r\n",
        "              yminmatrix.append(uppointy)\r\n",
        "            ymaxmatrix.append(downpointy)\r\n",
        "\r\n",
        "          #Append the keypoints of translator in array. Later we will segment and use them for embeddings\r\n",
        "          facearray.append(face0[person_index,:,:])\r\n",
        "          posearray.append(pose0[person_index,:,:])\r\n",
        "          lefthandarray.append(lefthand0[person_index,:,:])\r\n",
        "          righthandarray.append(righthand0[person_index,:,:])\r\n",
        "\r\n",
        "        \r\n",
        "        #This loop is for the segmentation, based on movement of sign translator in current and next frame\r\n",
        "        if people_present_flag == 1:\r\n",
        "          rightmost0 = np.amax(face0[:,:,0],axis = 1)\r\n",
        "          ###### If you expect the sign translator to be on the left side of the screen uncomment the definition of 'rightmost' below and comment out the definition of 'rightmost' above\r\n",
        "          #rightmost0 = np.amin(face0[:,:,0],axis = 1)\r\n",
        "          person_index0=np.argmax(rightmost0)\r\n",
        "          rightmost1 = np.amax(face1[:,:,0],axis = 1)\r\n",
        "          ###### If you expect the sign translator to be on the left side of the screen uncomment the definition of 'rightmost' below and comment out the definition of 'rightmost' above          \r\n",
        "          #rightmost1 = np.amin(face1[:,:,0],axis = 1)\r\n",
        "          person_index1=np.argmax(rightmost1)\r\n",
        "\r\n",
        "          #Distance between head and chest in pose keypoints. Useful to remove cases where the sign translator doesnt move much between frames but is not a stop frame\r\n",
        "          reference_distancey = pose0[person_index0,1,1] - pose0[person_index0,0,1] \r\n",
        "\r\n",
        "          #Mean of visible keypoints of the hands of the sign translator\r\n",
        "          lefthandxmean0 = np.sum(lefthand0[person_index0,:,0])/(np.count_nonzero(lefthand0[person_index0,:,0]))\r\n",
        "          lefthandymean0 = np.sum(lefthand0[person_index0,:,1])/(np.count_nonzero(lefthand0[person_index0,:,1]))\r\n",
        "          righthandxmean0 = np.sum(righthand0[person_index0,:,0])/(np.count_nonzero(righthand0[person_index0,:,0]))\r\n",
        "          righthandymean0 = np.sum(righthand0[person_index0,:,1])/(np.count_nonzero(righthand0[person_index0,:,1]))\r\n",
        "\r\n",
        "\r\n",
        "          lefthandxmean1 = np.sum(lefthand1[person_index1,:,0])/(np.count_nonzero(lefthand1[person_index1,:,0]))\r\n",
        "          lefthandymean1 = np.sum(lefthand1[person_index1,:,1])/(np.count_nonzero(lefthand1[person_index1,:,1]))\r\n",
        "          righthandxmean1 = np.sum(righthand1[person_index1,:,0])/(np.count_nonzero(righthand1[person_index1,:,0]))\r\n",
        "          righthandymean1 = np.sum(righthand1[person_index1,:,1])/(np.count_nonzero(righthand1[person_index1,:,1]))\r\n",
        "\r\n",
        "\r\n",
        "          #Distance between hands of the sign translator in frame\r\n",
        "          hand_distancex = abs(lefthandxmean0 - righthandxmean0) \r\n",
        "          hand_distancey = abs(lefthandymean0 - righthandymean0) \r\n",
        "          lefthand_frompose = abs(lefthandymean0 - pose0[person_index0,1,1])\r\n",
        "          righthand_frompose =  abs(righthandymean0 - pose0[person_index0,1,1])\r\n",
        "\r\n",
        "          #Change in the position of hands between consecutive frames\r\n",
        "          lefthandmeanx_change = abs((lefthandxmean1-lefthandxmean0)/lefthandxmean0)\r\n",
        "          lefthandmeany_change = abs((lefthandymean1-lefthandymean0)/lefthandymean0)\r\n",
        "          righthandmeanx_change = abs((righthandxmean1-righthandxmean0)/righthandxmean0)\r\n",
        "          righthandmeany_change = abs((righthandymean1-righthandymean0)/righthandymean0)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "          tolerance = 0.02 #How much percent change is tolerated to be in the current state (Segment/Not Segment)?\r\n",
        "\r\n",
        "          #Loop that determines when a frame is a start frame\r\n",
        "          if ((lefthandmeanx_change)> tolerance or (lefthandmeany_change) > tolerance or (righthandmeanx_change) > tolerance or (righthandmeany_change) > tolerance) and flag == False:\r\n",
        "            flag = True\r\n",
        "            frame_array.append(frame)\r\n",
        "\r\n",
        "          #Loop that determines when a frame is a stop frames. Alongwith minimal change in the coordinates, the distance based rules defined earlier have to be satisfied to avoid false positives\r\n",
        "          if (lefthandmeanx_change)< tolerance and (lefthandmeany_change) < tolerance and (righthandmeanx_change) < tolerance and (righthandmeany_change) < tolerance and flag == True and hand_distancex < 0.15*(reference_distancey) and hand_distancey < 0.15*(reference_distancey) and lefthand_frompose > 0.75*(reference_distancey) and righthand_frompose > 0.75*(reference_distancey):\r\n",
        "            frame_array.append(frame)\r\n",
        "            flag = False\r\n",
        "          \r\n",
        "\r\n",
        "      #Calculate the global coordinates for the sign language translator in a video\r\n",
        "      x1=min(xminmatrix)\r\n",
        "      y1=min(yminmatrix)\r\n",
        "      if y1<0:\r\n",
        "        y1 = 0\r\n",
        "      x2=max(xmaxmatrix)\r\n",
        "      y2=max(ymaxmatrix)\r\n",
        "\r\n",
        "      #Append the information for all the videos in the loop\r\n",
        "      vid_name_all.append(video_name)\r\n",
        "      x1_all.append(x1)\r\n",
        "      x2_all.append(x2)\r\n",
        "      y1_all.append(y1)\r\n",
        "      y2_all.append(y2)\r\n",
        "\r\n",
        "      face_tensor = np.stack(facearray)\r\n",
        "      pose_tensor = np.array(posearray)\r\n",
        "      lefthand_tensor = np.array(lefthandarray)\r\n",
        "      righthand_tensor = np.array(righthandarray)\r\n",
        "\r\n",
        "\r\n",
        "      #Save information about the keypoints of the sign translator in a video in 4 numpy arrays\r\n",
        "      np.save(output_dir+\"/\"+(video_name.split('.')[0])+\"_face_tensor\",face_tensor)\r\n",
        "      np.save(output_dir+\"/\"+(video_name.split('.')[0])+\"_pose_tensor\",pose_tensor)\r\n",
        "      np.save(output_dir+\"/\"+(video_name.split('.')[0])+\"_lefthand_tensor\",lefthand_tensor)\r\n",
        "      np.save(output_dir+\"/\"+(video_name.split('.')[0])+\"_righthand_tensor\",righthand_tensor)\r\n",
        "\r\n",
        "      #Divide start/stop frame numbers into timestamps\r\n",
        "      len_frame_tot = len(frame_array)\r\n",
        "      final_time = []\r\n",
        "      clip_location = video_path+\"/\"+video_name\r\n",
        "      time_stop = time_stamp_fn(num_frames,frame_array,clip_location)\r\n",
        "\r\n",
        "      start_times = time_stop[0:][::2]\r\n",
        "      end_times = time_stop[1:][::2]\r\n",
        "      if len(start_times) != len(end_times):\r\n",
        "        end_times.append('NaN')\r\n",
        "\r\n",
        "      timestamp_final = list(zip(start_times,end_times))  \r\n",
        "      timestamp_final = np.asarray(timestamp_final,dtype='float64')\r\n",
        "      timestamp_final_filtered = timestamp_final[ (timestamp_final[:,1] - timestamp_final[:,0]) > 2] #Remove segments less than 2 seconds\r\n",
        "      print(timestamp_final_filtered) \r\n",
        "      np.save(output_dir+\"/\"+(video_name.split('.')[0])+\"_timestamp\", timestamp_final_filtered) #Save final timestamps in numpy array\r\n",
        "      count_video = count_video + 1\r\n",
        "      print(\"Finished processing Video \", count_video)\r\n",
        "\r\n",
        "  except Exception as e:\r\n",
        "      print(e)\r\n",
        "      sys.exit(-1)\r\n",
        "\r\n",
        "#Save the sign translator coordinates of all videos in a csv file\r\n",
        "sign_translator_list = list(zip(vid_name_all,x1_all,x2_all,y1_all,y2_all))\r\n",
        "sign_translator_df = pd.DataFrame(sign_translator_list)\r\n",
        "sign_translator_df.columns =['Video_Name', 'x1', 'x2', 'y1','y2']\r\n",
        "sign_translator_df.to_csv(output_dir+\"/sign_translator_location.csv\",index=None)\r\n",
        "print(\"Finished processing All videos\")\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['video38.ts', 'video44.ts', 'video43.ts', 'video41.ts']\n",
            "video38.ts\n",
            "Finished making frames from video\n",
            "/content/drive/My Drive/frames/test_0.jpg\n",
            "/content/drive/My Drive/frames/test_1.jpg\n",
            "/content/drive/My Drive/frames/test_1.jpg\n",
            "/content/drive/My Drive/frames/test_2.jpg\n",
            "/content/drive/My Drive/frames/test_2.jpg\n",
            "/content/drive/My Drive/frames/test_3.jpg\n",
            "/content/drive/My Drive/frames/test_3.jpg\n",
            "/content/drive/My Drive/frames/test_4.jpg\n",
            "/content/drive/My Drive/frames/test_4.jpg\n",
            "/content/drive/My Drive/frames/test_5.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:288: RuntimeWarning: invalid value encountered in true_divide\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:289: RuntimeWarning: invalid value encountered in true_divide\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:290: RuntimeWarning: invalid value encountered in true_divide\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:291: RuntimeWarning: invalid value encountered in true_divide\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:294: RuntimeWarning: invalid value encountered in true_divide\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:295: RuntimeWarning: invalid value encountered in true_divide\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:296: RuntimeWarning: invalid value encountered in true_divide\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:297: RuntimeWarning: invalid value encountered in true_divide\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/frames/test_5.jpg\n",
            "/content/drive/My Drive/frames/test_6.jpg\n",
            "/content/drive/My Drive/frames/test_6.jpg\n",
            "/content/drive/My Drive/frames/test_7.jpg\n",
            "/content/drive/My Drive/frames/test_7.jpg\n",
            "/content/drive/My Drive/frames/test_8.jpg\n",
            "/content/drive/My Drive/frames/test_8.jpg\n",
            "/content/drive/My Drive/frames/test_9.jpg\n",
            "/content/drive/My Drive/frames/test_9.jpg\n",
            "/content/drive/My Drive/frames/test_10.jpg\n",
            "/content/drive/My Drive/frames/test_10.jpg\n",
            "/content/drive/My Drive/frames/test_11.jpg\n",
            "/content/drive/My Drive/frames/test_11.jpg\n",
            "/content/drive/My Drive/frames/test_12.jpg\n",
            "/content/drive/My Drive/frames/test_12.jpg\n",
            "/content/drive/My Drive/frames/test_13.jpg\n",
            "/content/drive/My Drive/frames/test_13.jpg\n",
            "/content/drive/My Drive/frames/test_14.jpg\n",
            "/content/drive/My Drive/frames/test_14.jpg\n",
            "/content/drive/My Drive/frames/test_15.jpg\n",
            "/content/drive/My Drive/frames/test_15.jpg\n",
            "/content/drive/My Drive/frames/test_16.jpg\n",
            "/content/drive/My Drive/frames/test_16.jpg\n",
            "/content/drive/My Drive/frames/test_17.jpg\n",
            "/content/drive/My Drive/frames/test_17.jpg\n",
            "/content/drive/My Drive/frames/test_18.jpg\n",
            "/content/drive/My Drive/frames/test_18.jpg\n",
            "/content/drive/My Drive/frames/test_19.jpg\n",
            "/content/drive/My Drive/frames/test_19.jpg\n",
            "/content/drive/My Drive/frames/test_20.jpg\n",
            "/content/drive/My Drive/frames/test_20.jpg\n",
            "/content/drive/My Drive/frames/test_21.jpg\n",
            "/content/drive/My Drive/frames/test_21.jpg\n",
            "/content/drive/My Drive/frames/test_22.jpg\n",
            "/content/drive/My Drive/frames/test_22.jpg\n",
            "/content/drive/My Drive/frames/test_23.jpg\n",
            "/content/drive/My Drive/frames/test_23.jpg\n",
            "/content/drive/My Drive/frames/test_24.jpg\n",
            "/content/drive/My Drive/frames/test_24.jpg\n",
            "/content/drive/My Drive/frames/test_25.jpg\n",
            "/content/drive/My Drive/frames/test_25.jpg\n",
            "/content/drive/My Drive/frames/test_26.jpg\n",
            "/content/drive/My Drive/frames/test_26.jpg\n",
            "/content/drive/My Drive/frames/test_27.jpg\n",
            "/content/drive/My Drive/frames/test_27.jpg\n",
            "/content/drive/My Drive/frames/test_28.jpg\n",
            "/content/drive/My Drive/frames/test_28.jpg\n",
            "/content/drive/My Drive/frames/test_29.jpg\n",
            "/content/drive/My Drive/frames/test_29.jpg\n",
            "/content/drive/My Drive/frames/test_30.jpg\n",
            "/content/drive/My Drive/frames/test_30.jpg\n",
            "/content/drive/My Drive/frames/test_31.jpg\n",
            "/content/drive/My Drive/frames/test_31.jpg\n",
            "/content/drive/My Drive/frames/test_32.jpg\n",
            "/content/drive/My Drive/frames/test_32.jpg\n",
            "/content/drive/My Drive/frames/test_33.jpg\n",
            "/content/drive/My Drive/frames/test_33.jpg\n",
            "/content/drive/My Drive/frames/test_34.jpg\n",
            "/content/drive/My Drive/frames/test_34.jpg\n",
            "/content/drive/My Drive/frames/test_35.jpg\n",
            "/content/drive/My Drive/frames/test_35.jpg\n",
            "/content/drive/My Drive/frames/test_36.jpg\n",
            "/content/drive/My Drive/frames/test_36.jpg\n",
            "/content/drive/My Drive/frames/test_37.jpg\n",
            "/content/drive/My Drive/frames/test_37.jpg\n",
            "/content/drive/My Drive/frames/test_38.jpg\n",
            "/content/drive/My Drive/frames/test_38.jpg\n",
            "/content/drive/My Drive/frames/test_39.jpg\n",
            "/content/drive/My Drive/frames/test_39.jpg\n",
            "/content/drive/My Drive/frames/test_40.jpg\n",
            "/content/drive/My Drive/frames/test_40.jpg\n",
            "/content/drive/My Drive/frames/test_41.jpg\n",
            "/content/drive/My Drive/frames/test_41.jpg\n",
            "/content/drive/My Drive/frames/test_42.jpg\n",
            "/content/drive/My Drive/frames/test_42.jpg\n",
            "/content/drive/My Drive/frames/test_43.jpg\n",
            "/content/drive/My Drive/frames/test_43.jpg\n",
            "/content/drive/My Drive/frames/test_44.jpg\n",
            "/content/drive/My Drive/frames/test_44.jpg\n",
            "/content/drive/My Drive/frames/test_45.jpg\n",
            "/content/drive/My Drive/frames/test_45.jpg\n",
            "/content/drive/My Drive/frames/test_46.jpg\n",
            "/content/drive/My Drive/frames/test_46.jpg\n",
            "/content/drive/My Drive/frames/test_47.jpg\n",
            "/content/drive/My Drive/frames/test_47.jpg\n",
            "/content/drive/My Drive/frames/test_48.jpg\n",
            "/content/drive/My Drive/frames/test_48.jpg\n",
            "/content/drive/My Drive/frames/test_49.jpg\n",
            "/content/drive/My Drive/frames/test_49.jpg\n",
            "/content/drive/My Drive/frames/test_50.jpg\n",
            "/content/drive/My Drive/frames/test_50.jpg\n",
            "/content/drive/My Drive/frames/test_51.jpg\n",
            "/content/drive/My Drive/frames/test_51.jpg\n",
            "/content/drive/My Drive/frames/test_52.jpg\n",
            "/content/drive/My Drive/frames/test_52.jpg\n",
            "/content/drive/My Drive/frames/test_53.jpg\n",
            "/content/drive/My Drive/frames/test_53.jpg\n",
            "/content/drive/My Drive/frames/test_54.jpg\n",
            "/content/drive/My Drive/frames/test_54.jpg\n",
            "/content/drive/My Drive/frames/test_55.jpg\n",
            "/content/drive/My Drive/frames/test_55.jpg\n",
            "/content/drive/My Drive/frames/test_56.jpg\n",
            "/content/drive/My Drive/frames/test_56.jpg\n",
            "/content/drive/My Drive/frames/test_57.jpg\n",
            "/content/drive/My Drive/frames/test_57.jpg\n",
            "/content/drive/My Drive/frames/test_58.jpg\n",
            "/content/drive/My Drive/frames/test_58.jpg\n",
            "/content/drive/My Drive/frames/test_59.jpg\n",
            "/content/drive/My Drive/frames/test_59.jpg\n",
            "/content/drive/My Drive/frames/test_60.jpg\n",
            "/content/drive/My Drive/frames/test_60.jpg\n",
            "/content/drive/My Drive/frames/test_61.jpg\n",
            "/content/drive/My Drive/frames/test_61.jpg\n",
            "/content/drive/My Drive/frames/test_62.jpg\n",
            "/content/drive/My Drive/frames/test_62.jpg\n",
            "/content/drive/My Drive/frames/test_63.jpg\n",
            "/content/drive/My Drive/frames/test_63.jpg\n",
            "/content/drive/My Drive/frames/test_64.jpg\n",
            "/content/drive/My Drive/frames/test_64.jpg\n",
            "/content/drive/My Drive/frames/test_65.jpg\n",
            "/content/drive/My Drive/frames/test_65.jpg\n",
            "/content/drive/My Drive/frames/test_66.jpg\n",
            "/content/drive/My Drive/frames/test_66.jpg\n",
            "/content/drive/My Drive/frames/test_67.jpg\n",
            "/content/drive/My Drive/frames/test_67.jpg\n",
            "/content/drive/My Drive/frames/test_68.jpg\n",
            "/content/drive/My Drive/frames/test_68.jpg\n",
            "/content/drive/My Drive/frames/test_69.jpg\n",
            "/content/drive/My Drive/frames/test_69.jpg\n",
            "/content/drive/My Drive/frames/test_70.jpg\n",
            "/content/drive/My Drive/frames/test_70.jpg\n",
            "/content/drive/My Drive/frames/test_71.jpg\n",
            "/content/drive/My Drive/frames/test_71.jpg\n",
            "/content/drive/My Drive/frames/test_72.jpg\n",
            "/content/drive/My Drive/frames/test_72.jpg\n",
            "/content/drive/My Drive/frames/test_73.jpg\n",
            "/content/drive/My Drive/frames/test_73.jpg\n",
            "/content/drive/My Drive/frames/test_74.jpg\n",
            "/content/drive/My Drive/frames/test_74.jpg\n",
            "/content/drive/My Drive/frames/test_75.jpg\n",
            "/content/drive/My Drive/frames/test_75.jpg\n",
            "/content/drive/My Drive/frames/test_76.jpg\n",
            "/content/drive/My Drive/frames/test_76.jpg\n",
            "/content/drive/My Drive/frames/test_77.jpg\n",
            "/content/drive/My Drive/frames/test_77.jpg\n",
            "/content/drive/My Drive/frames/test_78.jpg\n",
            "/content/drive/My Drive/frames/test_78.jpg\n",
            "/content/drive/My Drive/frames/test_79.jpg\n",
            "/content/drive/My Drive/frames/test_79.jpg\n",
            "/content/drive/My Drive/frames/test_80.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-113ab3413b3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mimageToProcess0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mdatum0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvInputData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimageToProcess0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mopWrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memplaceAndPop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVectorDatum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdatum0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mlefthand0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdatum0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandKeypoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mrighthand0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdatum0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandKeypoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}